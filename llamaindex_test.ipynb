{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Programming\\conversational-memory\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|██████████| 6.42k/6.42k [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|██████████| 9.19k/9.19k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 566M/566M [00:05<00:00, 94.5MB/s] \n",
      "Downloading data: 100%|██████████| 47.5M/47.5M [00:00<00:00, 66.0MB/s]\n",
      "Downloading data: 100%|██████████| 46.2M/46.2M [00:00<00:00, 68.6MB/s]\n",
      "Generating train split: 100%|██████████| 90447/90447 [00:12<00:00, 7360.69 examples/s] \n",
      "Generating validation split: 100%|██████████| 7405/7405 [00:00<00:00, 9530.27 examples/s] \n",
      "Generating test split: 100%|██████████| 7405/7405 [00:00<00:00, 10444.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-bsPbS3XexueSdupslq8eT3BlbkFJyvt59Ny04C7FOZs19o7n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: c9f6ea94-33f5-4e2c-b3a1-6d913b11eae9\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/paul_graham_essay.txt\"]\n",
    ").load_data()\n",
    "\n",
    "print(\"Document ID:\", documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index over the documents\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=\"http://localhost:19530\", dim=1536, overwrite=True\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, rm):\n",
    "        super().__init__()\n",
    "        self.retrieve = rm\n",
    "\n",
    "        # This signature indicates the task imposed on the COT module.\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        # Use milvus_rm to retrieve context for the question.\n",
    "        context = self.retrieve(question).passages\n",
    "        # COT module takes \"context, query\" and output \"answer\".\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(\n",
    "            context=[item.long_text for item in context], answer=prediction.answer\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
